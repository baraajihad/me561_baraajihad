{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c84e676-a298-426c-bae9-25b5be17269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, window_size, step_size):\n",
    "    for y in range(0, image.shape[0], step_size[1]):\n",
    "        for x in range(0, image.shape[1], step_size[0]):\n",
    "            yield (x, y, image[y: y + window_size[1], x: x + window_size[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a02c77e9-0a00-4778-b6ba-a5d7b360def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\bee\\Desktop')\n",
    "import Sliding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1495cc81-b335-4ce1-b2bb-074f79ed1d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bee\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.22.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc:  [1.3193242569312953, 0.9269982253057756, 0.6501839594583312, 2.0484493499712224, 0.5435326220906433, 0.9308168070109999, 1.1446440033271008, 0.5572674958680648, 0.7022031115837724, 0.7314457685488911, 1.7351451520453578, 3.3513141950964807, 2.29709903656141, 0.9860116486187209, 0.8952391552679773, 0.7723251790582846, 1.0645772856772537, 1.481582036807798, 0.6032052379240205, 1.1429689688122906, 0.6993035526884785, 1.325804155753206, 1.7094704641645233, 1.1945365812108166, 1.3952797256214406, 0.6058373065989073, 1.2571158024739302, 0.5800096466130453, 0.9323138141658331, 1.627227171661402, 0.9382103906654464, 0.5713176265443756, 1.146186118475799, 1.3695887773813515, 1.2537807364387565, 1.371203852955123, 1.9964170033763287, 1.5854938302241335, 0.9395305896779709, 0.8553222628507218, 1.4897704703236316, 1.1040726815326716, 0.6896473204624094, 2.1834921982241307, 1.2896292817352575, 3.6450548321870597, 3.0763771233855888, 2.5889270944563547, 3.4508976530505517, 1.2692645763287964, 3.502287777448478, 0.6471199898614914, 0.6961381708464369]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2,joblib\n",
    "import Sliding as sd\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import imutils\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "from skimage.transform import pyramid_gaussian\n",
    "\n",
    "\n",
    "image = cv2.imread(r'C:\\Users\\bee\\Desktop\\ppl.jpg')\n",
    "image = cv2.resize(image,(400,256))\n",
    "size = (64,128)\n",
    "step_size = (9,9)\n",
    "downscale = 1.25\n",
    "#List to store the detections\n",
    "detections = []\n",
    "#The current scale of the image \n",
    "scale = 0\n",
    "model = joblib.load(r'C:\\Users\\bee\\Desktop\\models.dat')\n",
    "for im_scaled in pyramid_gaussian(image, downscale = downscale):\n",
    "    #The list contains detections at the current scale\n",
    "    if im_scaled.shape[0] < size[1] or im_scaled.shape[1] < size[0]:\n",
    "        break\n",
    "    for (x, y, window) in sd.sliding_window(im_scaled, size, step_size):\n",
    "        if window.shape[0] != size[1] or window.shape[1] != size[0]:\n",
    "            continue\n",
    "        window = color.rgb2gray(window)\n",
    "            \n",
    "        fd=hog(window, orientations=9,pixels_per_cell=(8,8),visualize=False,cells_per_block=(3,3))\n",
    "        fd = fd.reshape(1, -1)\n",
    "        pred = model.predict(fd)\n",
    "        if pred == 1:\n",
    "                \n",
    "            if model.decision_function(fd) > 0.5:\n",
    "                detections.append((int(x * (downscale**scale)), int(y * (downscale**scale)), model.decision_function(fd), \n",
    "                int(size[0] * (downscale**scale)),\n",
    "                int(size[1] * (downscale**scale))))\n",
    " \n",
    "    scale += 1\n",
    "clone = image.copy()\n",
    "rects = np.array([[x, y, x + w, y + h] for (x, y, _, w, h) in detections])\n",
    "sc = [score[0] for (x, y, score, w, h) in detections]\n",
    "print (\"sc: \", sc)\n",
    "sc = np.array(sc)\n",
    "pick = non_max_suppression(rects, probs = sc, overlapThresh = 0.3)\n",
    "for(x1, y1, x2, y2) in pick:\n",
    "    cv2.rectangle(clone, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(clone,'Person',(x1-2,y1-2),1,0.75,(121,12,34),1)\n",
    "cv2.imshow('Person Detection',clone)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f0403-9ff4-40d4-baea-833fe3b5037c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
